{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rp9keXJlz7YC"
   },
   "source": [
    "## Libraries and Data Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-xRGn4hwz-KV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVI6ltZK06gj"
   },
   "source": [
    "# Downloading the Clinical trials 2021 collection [Start Here]\n",
    "\n",
    "2 GBs --> 20 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oP8PJMSS093b",
    "outputId": "0bafd060-548b-4b3d-fa70-cc5b20051f93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access denied with the following error:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecedu\\anaconda3\\lib\\site-packages\\gdown\\cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "\n",
      " \tCannot retrieve the public link of the file. You may need to change\n",
      "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
      "\n",
      "You may still be able to access the file from the browser:\n",
      "\n",
      "\t https://drive.google.com/uc?id=1oi3mnz6PQVt-tEMR6IQnqC0ab9IZ1iXx \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1oi3mnz6PQVt-tEMR6IQnqC0ab9IZ1iXx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UumR7MlW1Ntn"
   },
   "source": [
    "# Load the Dataframe\n",
    "\n",
    "2 GBs --> 18 secs, 375580 Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "OjCppo-30_Ue",
    "outputId": "0e564778-77c5-4c4d-e5e8-8ee950264aba"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/extracted_information.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m pickle_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/extracted_information.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load the data from the pickle file into a list of dictionaries\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpickle_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      9\u001b[0m     extracted_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/extracted_information.pkl'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Specify the path to the pickle file\n",
    "pickle_file_path = '/content/extracted_information.pkl'\n",
    "\n",
    "# Load the data from the pickle file into a list of dictionaries\n",
    "with open(pickle_file_path, 'rb') as file:\n",
    "    extracted_data = []\n",
    "    while True:\n",
    "        try:\n",
    "            document = pickle.load(file)\n",
    "            extracted_data.extend(document)\n",
    "        except EOFError:\n",
    "            break\n",
    "\n",
    "# Convert the list of dictionaries to a Pandas DataFrame\n",
    "df = pd.DataFrame(extracted_data)\n",
    "\n",
    "# Now 'df' is a Pandas DataFrame that contains the extracted information from the XML files.\n",
    "# You can use standard Pandas DataFrame operations to analyze and manipulate the data.\n",
    "# For example, you can print the first few rows of the DataFrame:\n",
    "display(df.head())\n",
    "print(f'Total number of documents: {len(df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXFJu4AT1XEi"
   },
   "source": [
    "# Analyze the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "id": "XtRWZ0yR3EnY",
    "outputId": "4efedde5-bedf-4323-f1c4-aa79009c286b"
   },
   "outputs": [],
   "source": [
    "# Set display options to show all columns and rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_rows', None)     # Show all rows\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FS_I61Nf27bA"
   },
   "source": [
    "### Count how many times a terms appears in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qw0I032W12C2",
    "outputId": "c7b41f2a-ea89-45eb-b86b-3aa841b6587e"
   },
   "outputs": [],
   "source": [
    "# Replace 'target_term' with the term you want to search for\n",
    "target_term = 'target_term'\n",
    "\n",
    "# Count occurrences of target_term in text_column\n",
    "term_count = df['detailed_description'].str.count(target_term).sum()\n",
    "print(f\"The term '{target_term}' appears {term_count} times in the 'detailed_description'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJFu22Bu3Z4b"
   },
   "source": [
    "### Display unique values of a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pEyJaB2p3cng",
    "outputId": "a0472d2a-df7f-4efd-e523-358c9e5e758d"
   },
   "outputs": [],
   "source": [
    "unique_values = df['study_type'].unique()\n",
    "print(\"Unique values in 'study_type':\")\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3xVdGyS4ICf"
   },
   "source": [
    "### Display some information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 670
    },
    "id": "izoULdc54Jru",
    "outputId": "50924f62-0f65-44f8-d7e6-669307a325ba"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "def plot_top_words_frequency(data_frame, column_name, top_n=13):\n",
    "    # Extract text from the specified column\n",
    "    text_data = \" \".join(data_frame[column_name])\n",
    "\n",
    "    # Tokenization and preprocessing\n",
    "    tokens = word_tokenize(text_data.lower())\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
    "\n",
    "    # Calculate word frequencies\n",
    "    word_freq = Counter(tokens)\n",
    "\n",
    "    # Get the top N most common words\n",
    "    top_words = word_freq.most_common(top_n)\n",
    "\n",
    "    # Extract words and frequencies for plotting\n",
    "    words = [word for word, freq in top_words]\n",
    "    frequencies = [freq for word, freq in top_words]\n",
    "\n",
    "    # Set seaborn style\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # Create a bar chart using Seaborn\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=frequencies, y=words, palette=\"Blues_d\")\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.ylabel(\"Words\")\n",
    "    plt.title(f\"Top {top_n} Most Common Words in '{column_name}'\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot top word frequencies from the 'text_column'\n",
    "plot_top_words_frequency(df, 'study_design_info_primary_purpose')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-E943L95SxQ"
   },
   "source": [
    "# Indexing the collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoeSjc5d52ZH"
   },
   "source": [
    "Installing PyTerrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z_waLxqQ4Mjb",
    "outputId": "37e16bd2-4f72-4162-8341-2e7be9c90b56"
   },
   "outputs": [],
   "source": [
    "!pip install python-terrier\n",
    "import pyterrier as pt\n",
    "pt.init(boot_packages=[\"com.github.terrierteam:terrier-prf:-SNAPSHOT\"])\n",
    "\n",
    "if not pt.started():\n",
    "  pt.init()\n",
    "\n",
    "from pyterrier.measures import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Izoe0Qc39V13"
   },
   "source": [
    "Creating a field to index per document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fwlxU-n4Jksw",
    "outputId": "0021b87c-d92b-4576-aca1-8dd338295f73"
   },
   "outputs": [],
   "source": [
    "# Display the column names in your DataFrame\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ae1uWFff64iM"
   },
   "outputs": [],
   "source": [
    "df[['detailed_description', 'nct_id']]\n",
    "df=df.rename(columns={\"nct_id\" : \"docno\"})\n",
    "#df=df.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RCtCCTU6GAj"
   },
   "source": [
    "In the following cell, you can index the dataframe's documents. The index, with all its data structures, is written into a directory called `index`.\n",
    "\n",
    "[10 minutes to index the whole Collection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1YvLhEOS6V8w",
    "outputId": "a4facde2-cb1b-4932-fb7a-5ba291bbe356"
   },
   "outputs": [],
   "source": [
    "# The following line allows to set a property in Terrier’s global properties configuration. Example:\n",
    "\n",
    "## Specify where, and if it should overwrite other indices\n",
    "indexer = pt.DFIndexer(\"./index_sampledocs\", overwrite=True, stemmer= None, stopwords=True) #PorterStemmer\n",
    "\n",
    "## What it should index? This is a reference to the index\n",
    "index_ref = indexer.index(df[\"detailed_description\"], df[\"docno\"])\n",
    "print(index_ref.toString())\n",
    "\n",
    "## Printing the files related to the index\n",
    "!ls -lh index_sampledocs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzKi8KRr9gi6"
   },
   "source": [
    "Printing some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OrbHBblI55nk"
   },
   "outputs": [],
   "source": [
    "# Load the index, print the statistics\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "print(index.getCollectionStatistics().toString())\n",
    "print(index.getMetaIndex().getKeys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNKTJF990sSu"
   },
   "source": [
    "Ok, so this object refers to Terrier's [`Index`](http://terrier.org/docs/current/javadoc/org/terrier/structures/Index.html) type. Check the linked Javadoc – you will see that this Java object has methods such as:\n",
    " - `getCollectionStatistics()`\n",
    " - `getInvertedIndex()`\n",
    " - `getLexicon()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kgqidqZ02oj"
   },
   "outputs": [],
   "source": [
    "index = pt.IndexFactory.of(index_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwbp94gh86pw"
   },
   "source": [
    "Terrier removes standard stopwords and applies Porter's stemmer by default.\n",
    "\n",
    "Further:\n",
    " - `Nt` is the number of unique documents that each term occurs in – this is useful for calculating IDF.\n",
    " - `TF` is the total number of occurrences – some weighting models use this instead of Nt.\n",
    " - The numbers in the `@{}` are a pointer – they tell Terrier where the postings are for that term in the inverted index data structure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcqYxi481yZV"
   },
   "source": [
    "## Getting term statistics:\n",
    "One can use the square bracket notation to lookup terms in Terrier's lexicon:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZmi9498-Ijw"
   },
   "outputs": [],
   "source": [
    "print(index.getCollectionStatistics().toString())\n",
    "\n",
    "for kv in index.getLexicon():\n",
    "  print(\"%s -> %s\" % (kv.getKey(), kv.getValue().toString()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOSdVAr-CGRf"
   },
   "source": [
    "### Searching an Index\n",
    "\n",
    "One way to search in PyTerrier is called `BatchRetrieve`. BatchRetrieve is configured by specifying an index and a weighting model (`Tf` in our example).\n",
    "\n",
    "MODELS: http://terrier.org/docs/current/javadoc/org/terrier/matching/models/package-summary.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XtK93nwXCF5C"
   },
   "outputs": [],
   "source": [
    "# Setting the retrieval pipeline and model\n",
    "br = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n",
    "#As I am using a single query (that I manually provide I use search)\n",
    "br.search(\"injury\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHqSfTCtDM2T"
   },
   "source": [
    "So the `search()` method returns a dataframe with columns:\n",
    " - `qid`: this is by default \"1\", since it's our first and only query\n",
    " - `docid`: Terrier' internal integer for each document\n",
    " - `docno`: the external (string) unique identifier for each document\n",
    " - `score`: since we use the `Tf` weighting model, this score corresponds the total frequency of the query (terms) in each document\n",
    " - `rank`: A handy attribute showing the descending order by score\n",
    " - `query`: the input query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNcnenXe5Mfp"
   },
   "source": [
    "### Experiment with Query Language\n",
    "\n",
    "- Based on the query language supported by Terrier, create 2- 3 adhoc queries (by hand).\n",
    "- https://github.com/terrier-org/terrier-core/blob/5.x/doc/querylanguage.md\n",
    "\n",
    "- Use different relevance models and different query languages to\n",
    "search for your queries in the collection.\n",
    "- http://terrier.org/docs/current/javadoc/org/terrier/matching/models/package-summary.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cg8AGzCibdPG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOxM60uEAzMO"
   },
   "source": [
    "# Loading queries and qrels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rg8BdW0eCH4d"
   },
   "source": [
    "We will use ir_datasets to obtain the queries and the qrels\n",
    "https://ir-datasets.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-ZMwJk6C-O4"
   },
   "outputs": [],
   "source": [
    "\"\"\"pip install beautifulsoup4\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwiNWhUfDAFj"
   },
   "outputs": [],
   "source": [
    "\"\"\"import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "# XML data\n",
    "xml_data = '''\n",
    "<topics task=\"2021 TREC Clinical Trials\">\n",
    "    <topic number=\"1\"> A 19-year-old male came to clinic with some sexual concern. He recently engaged in a relationship and is worried about the satisfaction of his girlfriend. He has a \"baby face\" according to his girlfriend's statement and he is not as muscular as his classmates. On physical examination, there is some pubic hair and poorly developed secondary sexual characteristics. He is unable to detect coffee smell during the examination, but the visual acuity is normal. Ultrasound reveals the testes volume of 1-2 ml. The hormonal evaluation showed serum testosterone level of 65 ng/dL with low levels of GnRH. </topic>\n",
    "    <topic number=\"2\"> A 32-year-old woman comes to the hospital with vaginal spotting. Her last menstrual period was 10 weeks ago. She has regular menses lasting for 6 days and repeating every 29 days. Medical history is significant for appendectomy and several complicated UTIs. She has multiple male partners, and she is inconsistent with using barrier contraceptives. Vital signs are normal. Serum β-hCG level is 1800 mIU/mL, and a repeat level after 2 days shows an abnormal rise to 2100 mIU/mL. Pelvic ultrasound reveals a thin endometrium with no gestational sac in the uterus. </topic>\n",
    "</topics>\n",
    "'''\n",
    "\n",
    "# Parse XML data\n",
    "root = ET.fromstring(xml_data)\n",
    "\n",
    "# Extract topics into a DataFrame\n",
    "topics_data = []\n",
    "for topic_elem in root.findall('.//topic'):\n",
    "    number = topic_elem.get('number')\n",
    "    text = topic_elem.text.strip()\n",
    "    topics_data.append({'number': number, 'text': text})\n",
    "\n",
    "# Create DataFrame\n",
    "topics_df = pd.DataFrame(topics_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(topics_df)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qNFCpTTfA1NS"
   },
   "outputs": [],
   "source": [
    "\"\"\"# Queries\n",
    "#!pip install --upgrade ir_datasets\n",
    "dataset = pt.get_dataset(topics_df)\n",
    "queries = dataset.get_topics(variant='text')\n",
    "display(queries)\n",
    "\n",
    "#Qrels\n",
    "!gdown --id 1RYHxr2sM9Hd2C2iRI_NXzO4RY71Adu-p\n",
    "\n",
    "path_to_qrels = 'clinical_qrels22.txt'\n",
    "qrels = pd.read_csv(path_to_qrels, names=['qid','Q0','docno','label'],sep=\" \",header=None)\n",
    "qrels = qrels.drop(columns=['Q0'])\n",
    "qrels[\"qid\"] = qrels[\"qid\"].astype(str)\n",
    "qrels[\"docno\"] = qrels[\"docno\"].astype(str)\n",
    "display(qrels.head(2))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0b80Hk2EpBfG"
   },
   "outputs": [],
   "source": [
    "# Queries\n",
    "!pip install --upgrade ir_datasets\n",
    "dataset = pt.get_dataset('irds:clinicaltrials/2021/trec-ct-2022')\n",
    "queries = dataset.get_topics(variant='text')\n",
    "display(queries)\n",
    "\n",
    "#Qrels\n",
    "!gdown --id 1RYHxr2sM9Hd2C2iRI_NXzO4RY71Adu-p\n",
    "\n",
    "path_to_qrels = 'clinical_qrels22.txt'\n",
    "qrels = pd.read_csv(path_to_qrels, names=['qid','Q0','docno','label'],sep=\" \",header=None)\n",
    "qrels = qrels.drop(columns=['Q0'])\n",
    "qrels[\"qid\"] = qrels[\"qid\"].astype(str)\n",
    "qrels[\"docno\"] = qrels[\"docno\"].astype(str)\n",
    "display(qrels.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uF-ZwNEELrC"
   },
   "source": [
    "# Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpxh60h7EO8c"
   },
   "outputs": [],
   "source": [
    "## Set a retrieval model or pipeline\n",
    "\n",
    "## Evaluation Measures\n",
    "####Relevance labels of 2 are considered as relevant\n",
    "metrics_eval = [\n",
    " RR(rel=2)@1000,\n",
    " P(rel=2)@1 , P(rel=2)@5 , P(rel=2)@10 , P(rel=2)@25 , P(rel=2)@30, P(rel=2)@75,\n",
    " Rprec(rel=2),\n",
    " R(rel=2)@10, R(rel=2)@25,\n",
    "]\n",
    "\n",
    "## Perform retrieval\n",
    "#Evaluate\n",
    "results_all_des = pt.Experiment(\n",
    "    [bm25],\n",
    "    queries,\n",
    "    qrels,\n",
    "    eval_metrics=metrics_eval,\n",
    "    names=[\"bm25\"\n",
    "           ],\n",
    "    baseline=0,\n",
    "    perquery = False,\n",
    ")\n",
    "display(results_all_des)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lB58qZJArRaZ"
   },
   "source": [
    "## ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install flask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load your DataFrame and necessary functions here\n",
    "# For example, load the DataFrame from the pickled file\n",
    "\n",
    "# Load the DataFrame\n",
    "pickle_file_path = 'path_to_your_pickle_file.pkl'\n",
    "with open(pickle_file_path, 'rb') as file:\n",
    "    df = pickle.load(file)\n",
    "\n",
    "# Function to perform search\n",
    "def perform_search(query):\n",
    "    # Perform search operation in your DataFrame\n",
    "    # Replace this with your actual search logic\n",
    "    results = df[df['detailed_description'].str.contains(query, case=False)]\n",
    "    return results\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/search', methods=['GET'])\n",
    "def search():\n",
    "    query = request.args.get('query')\n",
    "    results = perform_search(query)\n",
    "    return render_template('results.html', query=query, results=results.to_dict(orient='records'))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
